{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "warnings.filterwarnings('ignore')\n",
    "#train.drop(['education'], axis=1,inplace=True)\n",
    "#train.drop(['relationship'], axis=1,inplace=True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label = train['income']\n",
    "train.drop(['income'], axis=1, inplace=True)\n",
    "\n",
    "train = pd.get_dummies(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8569047 , 0.84912476, 0.85218116, 0.854404  , 0.85579328,\n",
       "       0.86190609, 0.85495971, 0.84745763, 0.86079467, 0.85376703])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100,max_features='sqrt',max_depth=None,min_samples_split=2,bootstrap=True)\n",
    "rf_scores = cross_val_score(rf_clf,train,y_label,cv=10)\n",
    "rf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf.fit(train,y_label)\n",
    "importances=rf_clf.feature_importances_\n",
    "names=train.columns.values.tolist()\n",
    "sort_lst=sorted(zip(map(lambda x: round(x,3),importances),names), reverse=True)\n",
    "#importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = pd.read_csv(\"train.csv\")\n",
    "train_new.drop(['income'], axis=1,inplace=True)\n",
    "\n",
    "new_country = []\n",
    "for item in list(train_new['native-country']):\n",
    "    if item != 'United-States':\n",
    "        new_country.append('Others')\n",
    "    else:\n",
    "        new_country.append(item)\n",
    "        \n",
    "\n",
    "train_new['native-country'] = new_country\n",
    "train_new = pd.get_dummies(train_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized Score Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "\n",
    "def diff(pred, x_test):\n",
    "    gender = list(x_test)\n",
    "    g0_actual = [i for i,label in enumerate(gender) if label==0]\n",
    "    g1_actual = [i for i,label in enumerate(gender) if label==1]\n",
    "    pred_1 = [i for i,label in enumerate(pred) if label==1]\n",
    "    \n",
    "    diff = abs((len(set(g0_actual)&set(pred_1))/len(g0_actual))-(len(set(g1_actual)&set(pred_1))/len(g1_actual)))\n",
    "    return diff\n",
    "\n",
    "def score(diff, accuracy):\n",
    "    if diff<=0.1:\n",
    "        return accuracy\n",
    "    else:\n",
    "        score=accuracy-7**(diff-0.1)+1\n",
    "        return score\n",
    "\n",
    "def loss_function(y,y_pred,greater_is_better=True):\n",
    "    acc=(y==y_pred).mean()\n",
    "    diff_=diff(y,train['gender'])\n",
    "    return score(diff,acc)\n",
    "\n",
    "my_scorer=make_scorer(loss_function,greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8000444592641992"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "best_score_lr=0\n",
    "for c in [0.001,0.01,0.1,1,10,50]:\n",
    "    for weight in [None,'balanced']:\n",
    "        fair_=[]\n",
    "        time=0\n",
    "        while (time<5):\n",
    "            x_train,x_test,y_train,y_test = train_test_split(train_new,y_label,test_size=0.25,random_state=None)\n",
    "            lr = LogisticRegression(penalty='l2',class_weight=weight,C=c).fit(x_train,y_train)\n",
    "            acc=lr.score(x_test,y_test)\n",
    "            pred = list(lr.predict(x_test))\n",
    "            gender = list(x_test['gender'])\n",
    "            g0_act = [i for i,label in enumerate(gender) if label==0]\n",
    "            g1_act = [i for i,label in enumerate(gender) if label==1]\n",
    "            label_1_pred = [i for i,label in enumerate(pred) if label==1]\n",
    "            \n",
    "            diff=abs((len(set(g0_act)&set(label_1_pred))/len(g0_act))-(len(set(g1_act)&set(label_1_pred))/len(g1_act)))\n",
    "            if diff <= 0.1:\n",
    "                fair_.append(acc)\n",
    "            else:\n",
    "                acc = acc-7**(diff-0.1)+1\n",
    "                fair_.append(acc)\n",
    "            time += 1\n",
    "            \n",
    "        mean = np.mean(fair_)\n",
    "        if mean > best_score_lr:\n",
    "            best_score_lr = mean\n",
    "            best_param_lr = {'class_weight':weight,'C':c}\n",
    "\n",
    "best_score_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii.XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7535037996958146"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "best_score_xgb = 0\n",
    "for est in [50,100,500]:\n",
    "    for lr in [0.0005,0.001,0.005,0.1,1]:\n",
    "        fair_=[]\n",
    "        time=0\n",
    "        while (time<5):\n",
    "            x_train,x_test,y_train,y_test = train_test_split(train_new,y_label,test_size=0.25,random_state=None)\n",
    "            xgb_lr = xgb.XGBClassifier(learning_rate=lr, n_estimators=est).fit(x_train,y_train)\n",
    "            acc=xgb_lr.score(x_test,y_test)\n",
    "            pred = list(xgb_lr.predict(x_test))\n",
    "            gender = list(x_test['gender'])\n",
    "            g0_act = [i for i,label in enumerate(gender) if label==0]\n",
    "            g1_act = [i for i,label in enumerate(gender) if label==1]\n",
    "            label_1_pred = [i for i,label in enumerate(pred) if label==1]\n",
    "            \n",
    "            diff=abs((len(set(g0_act)&set(label_1_pred))/len(g0_act))-(len(set(g1_act)&set(label_1_pred))/len(g1_act)))\n",
    "            if diff <= 0.1:\n",
    "                fair_.append(acc)\n",
    "            else:\n",
    "                acc = acc-7**(diff-0.1)+1\n",
    "                fair_.append(acc)\n",
    "            time += 1\n",
    "            \n",
    "        mean = np.mean(fair_)\n",
    "        if mean > best_score_xgb:\n",
    "            best_score_xgb = mean\n",
    "            best_param_xgb = {'n_estimators':est, 'learning_rate':lr}\n",
    "            \n",
    "best_score_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
